{
  "best_metric": 0.3233458697795868,
  "best_model_checkpoint": "./model\\checkpoint-3125",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3125,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016,
      "grad_norm": 1.1644463539123535,
      "learning_rate": 5e-05,
      "loss": 0.6878,
      "step": 50
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.0798521041870117,
      "learning_rate": 4.959677419354839e-05,
      "loss": 0.6761,
      "step": 100
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.764817237854004,
      "learning_rate": 4.9193548387096775e-05,
      "loss": 0.6131,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.6474970579147339,
      "learning_rate": 4.8790322580645164e-05,
      "loss": 0.4125,
      "step": 200
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.280308246612549,
      "learning_rate": 4.839516129032258e-05,
      "loss": 0.3715,
      "step": 250
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.6575160622596741,
      "learning_rate": 4.799193548387097e-05,
      "loss": 0.3586,
      "step": 300
    },
    {
      "epoch": 0.112,
      "grad_norm": 2.6644446849823,
      "learning_rate": 4.7588709677419355e-05,
      "loss": 0.312,
      "step": 350
    },
    {
      "epoch": 0.128,
      "grad_norm": 2.1915833950042725,
      "learning_rate": 4.7185483870967745e-05,
      "loss": 0.4015,
      "step": 400
    },
    {
      "epoch": 0.144,
      "grad_norm": 3.496879816055298,
      "learning_rate": 4.6782258064516134e-05,
      "loss": 0.3446,
      "step": 450
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.844330310821533,
      "learning_rate": 4.637903225806452e-05,
      "loss": 0.3559,
      "step": 500
    },
    {
      "epoch": 0.176,
      "grad_norm": 4.516214847564697,
      "learning_rate": 4.5975806451612906e-05,
      "loss": 0.3045,
      "step": 550
    },
    {
      "epoch": 0.192,
      "grad_norm": 2.6653647422790527,
      "learning_rate": 4.5572580645161296e-05,
      "loss": 0.3737,
      "step": 600
    },
    {
      "epoch": 0.208,
      "grad_norm": 3.9165472984313965,
      "learning_rate": 4.5169354838709685e-05,
      "loss": 0.309,
      "step": 650
    },
    {
      "epoch": 0.224,
      "grad_norm": 6.627870082855225,
      "learning_rate": 4.476612903225806e-05,
      "loss": 0.3466,
      "step": 700
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.414997100830078,
      "learning_rate": 4.436290322580645e-05,
      "loss": 0.3898,
      "step": 750
    },
    {
      "epoch": 0.256,
      "grad_norm": 4.925975799560547,
      "learning_rate": 4.395967741935484e-05,
      "loss": 0.3098,
      "step": 800
    },
    {
      "epoch": 0.272,
      "grad_norm": 4.6265740394592285,
      "learning_rate": 4.355645161290322e-05,
      "loss": 0.2435,
      "step": 850
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.684910774230957,
      "learning_rate": 4.316129032258065e-05,
      "loss": 0.3042,
      "step": 900
    },
    {
      "epoch": 0.304,
      "grad_norm": 7.892765045166016,
      "learning_rate": 4.275806451612903e-05,
      "loss": 0.3464,
      "step": 950
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.7632977962493896,
      "learning_rate": 4.235483870967742e-05,
      "loss": 0.383,
      "step": 1000
    },
    {
      "epoch": 0.336,
      "grad_norm": 2.9228084087371826,
      "learning_rate": 4.1951612903225804e-05,
      "loss": 0.3266,
      "step": 1050
    },
    {
      "epoch": 0.352,
      "grad_norm": 4.932539939880371,
      "learning_rate": 4.154838709677419e-05,
      "loss": 0.3305,
      "step": 1100
    },
    {
      "epoch": 0.368,
      "grad_norm": 8.162184715270996,
      "learning_rate": 4.114516129032258e-05,
      "loss": 0.2495,
      "step": 1150
    },
    {
      "epoch": 0.384,
      "grad_norm": 2.792579412460327,
      "learning_rate": 4.0741935483870965e-05,
      "loss": 0.3684,
      "step": 1200
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.149258136749268,
      "learning_rate": 4.0338709677419355e-05,
      "loss": 0.2934,
      "step": 1250
    },
    {
      "epoch": 0.416,
      "grad_norm": 4.772824764251709,
      "learning_rate": 3.9935483870967745e-05,
      "loss": 0.3633,
      "step": 1300
    },
    {
      "epoch": 0.432,
      "grad_norm": 6.070931911468506,
      "learning_rate": 3.9532258064516134e-05,
      "loss": 0.3316,
      "step": 1350
    },
    {
      "epoch": 0.448,
      "grad_norm": 4.3043599128723145,
      "learning_rate": 3.912903225806452e-05,
      "loss": 0.2851,
      "step": 1400
    },
    {
      "epoch": 0.464,
      "grad_norm": 5.94843053817749,
      "learning_rate": 3.8725806451612906e-05,
      "loss": 0.353,
      "step": 1450
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.89117956161499,
      "learning_rate": 3.8322580645161296e-05,
      "loss": 0.2986,
      "step": 1500
    },
    {
      "epoch": 0.496,
      "grad_norm": 6.859813213348389,
      "learning_rate": 3.791935483870968e-05,
      "loss": 0.3454,
      "step": 1550
    },
    {
      "epoch": 0.512,
      "grad_norm": 10.335606575012207,
      "learning_rate": 3.751612903225807e-05,
      "loss": 0.308,
      "step": 1600
    },
    {
      "epoch": 0.528,
      "grad_norm": 5.061906814575195,
      "learning_rate": 3.711290322580646e-05,
      "loss": 0.3035,
      "step": 1650
    },
    {
      "epoch": 0.544,
      "grad_norm": 4.868542671203613,
      "learning_rate": 3.670967741935484e-05,
      "loss": 0.34,
      "step": 1700
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.067354202270508,
      "learning_rate": 3.630645161290322e-05,
      "loss": 0.3565,
      "step": 1750
    },
    {
      "epoch": 0.576,
      "grad_norm": 7.49595308303833,
      "learning_rate": 3.590322580645161e-05,
      "loss": 0.2608,
      "step": 1800
    },
    {
      "epoch": 0.592,
      "grad_norm": 5.433791160583496,
      "learning_rate": 3.55e-05,
      "loss": 0.3157,
      "step": 1850
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.4015689492225647,
      "learning_rate": 3.5096774193548385e-05,
      "loss": 0.2856,
      "step": 1900
    },
    {
      "epoch": 0.624,
      "grad_norm": 12.318196296691895,
      "learning_rate": 3.4693548387096775e-05,
      "loss": 0.288,
      "step": 1950
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.2405481338500977,
      "learning_rate": 3.4290322580645164e-05,
      "loss": 0.3876,
      "step": 2000
    },
    {
      "epoch": 0.656,
      "grad_norm": 10.442646980285645,
      "learning_rate": 3.388709677419355e-05,
      "loss": 0.3319,
      "step": 2050
    },
    {
      "epoch": 0.672,
      "grad_norm": 6.87216854095459,
      "learning_rate": 3.3483870967741936e-05,
      "loss": 0.2799,
      "step": 2100
    },
    {
      "epoch": 0.688,
      "grad_norm": 5.744488716125488,
      "learning_rate": 3.3080645161290326e-05,
      "loss": 0.3027,
      "step": 2150
    },
    {
      "epoch": 0.704,
      "grad_norm": 4.178797721862793,
      "learning_rate": 3.267741935483871e-05,
      "loss": 0.3076,
      "step": 2200
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.387663841247559,
      "learning_rate": 3.22741935483871e-05,
      "loss": 0.2566,
      "step": 2250
    },
    {
      "epoch": 0.736,
      "grad_norm": 12.338805198669434,
      "learning_rate": 3.187096774193549e-05,
      "loss": 0.319,
      "step": 2300
    },
    {
      "epoch": 0.752,
      "grad_norm": 9.47064208984375,
      "learning_rate": 3.146774193548388e-05,
      "loss": 0.3279,
      "step": 2350
    },
    {
      "epoch": 0.768,
      "grad_norm": 4.169252872467041,
      "learning_rate": 3.106451612903226e-05,
      "loss": 0.2932,
      "step": 2400
    },
    {
      "epoch": 0.784,
      "grad_norm": 2.774731159210205,
      "learning_rate": 3.066129032258065e-05,
      "loss": 0.3068,
      "step": 2450
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.9395341873168945,
      "learning_rate": 3.0258064516129032e-05,
      "loss": 0.3354,
      "step": 2500
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.4323805272579193,
      "learning_rate": 2.985483870967742e-05,
      "loss": 0.3141,
      "step": 2550
    },
    {
      "epoch": 0.832,
      "grad_norm": 3.2528464794158936,
      "learning_rate": 2.9451612903225805e-05,
      "loss": 0.2539,
      "step": 2600
    },
    {
      "epoch": 0.848,
      "grad_norm": 11.073655128479004,
      "learning_rate": 2.9048387096774194e-05,
      "loss": 0.2999,
      "step": 2650
    },
    {
      "epoch": 0.864,
      "grad_norm": 7.643585205078125,
      "learning_rate": 2.864516129032258e-05,
      "loss": 0.3533,
      "step": 2700
    },
    {
      "epoch": 0.88,
      "grad_norm": 8.08065128326416,
      "learning_rate": 2.8241935483870967e-05,
      "loss": 0.2491,
      "step": 2750
    },
    {
      "epoch": 0.896,
      "grad_norm": 1.0611209869384766,
      "learning_rate": 2.7838709677419356e-05,
      "loss": 0.2606,
      "step": 2800
    },
    {
      "epoch": 0.912,
      "grad_norm": 7.269674301147461,
      "learning_rate": 2.7435483870967742e-05,
      "loss": 0.384,
      "step": 2850
    },
    {
      "epoch": 0.928,
      "grad_norm": 9.711913108825684,
      "learning_rate": 2.7032258064516132e-05,
      "loss": 0.3593,
      "step": 2900
    },
    {
      "epoch": 0.944,
      "grad_norm": 10.712981224060059,
      "learning_rate": 2.6629032258064518e-05,
      "loss": 0.3175,
      "step": 2950
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.150750160217285,
      "learning_rate": 2.6233870967741936e-05,
      "loss": 0.2926,
      "step": 3000
    },
    {
      "epoch": 0.976,
      "grad_norm": 4.064871311187744,
      "learning_rate": 2.5830645161290323e-05,
      "loss": 0.2468,
      "step": 3050
    },
    {
      "epoch": 0.992,
      "grad_norm": 2.957528591156006,
      "learning_rate": 2.5427419354838712e-05,
      "loss": 0.2061,
      "step": 3100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.3233458697795868,
      "eval_runtime": 208.4344,
      "eval_samples_per_second": 119.942,
      "eval_steps_per_second": 14.993,
      "step": 3125
    }
  ],
  "logging_steps": 50,
  "max_steps": 6250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "total_flos": 1684242585600000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
