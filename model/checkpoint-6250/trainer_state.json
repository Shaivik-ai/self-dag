{
  "best_metric": 0.2865026593208313,
  "best_model_checkpoint": "./model\\checkpoint-6250",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 6250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016,
      "grad_norm": 1.1644463539123535,
      "learning_rate": 5e-05,
      "loss": 0.6878,
      "step": 50
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.0798521041870117,
      "learning_rate": 4.959677419354839e-05,
      "loss": 0.6761,
      "step": 100
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.764817237854004,
      "learning_rate": 4.9193548387096775e-05,
      "loss": 0.6131,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.6474970579147339,
      "learning_rate": 4.8790322580645164e-05,
      "loss": 0.4125,
      "step": 200
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.280308246612549,
      "learning_rate": 4.839516129032258e-05,
      "loss": 0.3715,
      "step": 250
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.6575160622596741,
      "learning_rate": 4.799193548387097e-05,
      "loss": 0.3586,
      "step": 300
    },
    {
      "epoch": 0.112,
      "grad_norm": 2.6644446849823,
      "learning_rate": 4.7588709677419355e-05,
      "loss": 0.312,
      "step": 350
    },
    {
      "epoch": 0.128,
      "grad_norm": 2.1915833950042725,
      "learning_rate": 4.7185483870967745e-05,
      "loss": 0.4015,
      "step": 400
    },
    {
      "epoch": 0.144,
      "grad_norm": 3.496879816055298,
      "learning_rate": 4.6782258064516134e-05,
      "loss": 0.3446,
      "step": 450
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.844330310821533,
      "learning_rate": 4.637903225806452e-05,
      "loss": 0.3559,
      "step": 500
    },
    {
      "epoch": 0.176,
      "grad_norm": 4.516214847564697,
      "learning_rate": 4.5975806451612906e-05,
      "loss": 0.3045,
      "step": 550
    },
    {
      "epoch": 0.192,
      "grad_norm": 2.6653647422790527,
      "learning_rate": 4.5572580645161296e-05,
      "loss": 0.3737,
      "step": 600
    },
    {
      "epoch": 0.208,
      "grad_norm": 3.9165472984313965,
      "learning_rate": 4.5169354838709685e-05,
      "loss": 0.309,
      "step": 650
    },
    {
      "epoch": 0.224,
      "grad_norm": 6.627870082855225,
      "learning_rate": 4.476612903225806e-05,
      "loss": 0.3466,
      "step": 700
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.414997100830078,
      "learning_rate": 4.436290322580645e-05,
      "loss": 0.3898,
      "step": 750
    },
    {
      "epoch": 0.256,
      "grad_norm": 4.925975799560547,
      "learning_rate": 4.395967741935484e-05,
      "loss": 0.3098,
      "step": 800
    },
    {
      "epoch": 0.272,
      "grad_norm": 4.6265740394592285,
      "learning_rate": 4.355645161290322e-05,
      "loss": 0.2435,
      "step": 850
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.684910774230957,
      "learning_rate": 4.316129032258065e-05,
      "loss": 0.3042,
      "step": 900
    },
    {
      "epoch": 0.304,
      "grad_norm": 7.892765045166016,
      "learning_rate": 4.275806451612903e-05,
      "loss": 0.3464,
      "step": 950
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.7632977962493896,
      "learning_rate": 4.235483870967742e-05,
      "loss": 0.383,
      "step": 1000
    },
    {
      "epoch": 0.336,
      "grad_norm": 2.9228084087371826,
      "learning_rate": 4.1951612903225804e-05,
      "loss": 0.3266,
      "step": 1050
    },
    {
      "epoch": 0.352,
      "grad_norm": 4.932539939880371,
      "learning_rate": 4.154838709677419e-05,
      "loss": 0.3305,
      "step": 1100
    },
    {
      "epoch": 0.368,
      "grad_norm": 8.162184715270996,
      "learning_rate": 4.114516129032258e-05,
      "loss": 0.2495,
      "step": 1150
    },
    {
      "epoch": 0.384,
      "grad_norm": 2.792579412460327,
      "learning_rate": 4.0741935483870965e-05,
      "loss": 0.3684,
      "step": 1200
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.149258136749268,
      "learning_rate": 4.0338709677419355e-05,
      "loss": 0.2934,
      "step": 1250
    },
    {
      "epoch": 0.416,
      "grad_norm": 4.772824764251709,
      "learning_rate": 3.9935483870967745e-05,
      "loss": 0.3633,
      "step": 1300
    },
    {
      "epoch": 0.432,
      "grad_norm": 6.070931911468506,
      "learning_rate": 3.9532258064516134e-05,
      "loss": 0.3316,
      "step": 1350
    },
    {
      "epoch": 0.448,
      "grad_norm": 4.3043599128723145,
      "learning_rate": 3.912903225806452e-05,
      "loss": 0.2851,
      "step": 1400
    },
    {
      "epoch": 0.464,
      "grad_norm": 5.94843053817749,
      "learning_rate": 3.8725806451612906e-05,
      "loss": 0.353,
      "step": 1450
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.89117956161499,
      "learning_rate": 3.8322580645161296e-05,
      "loss": 0.2986,
      "step": 1500
    },
    {
      "epoch": 0.496,
      "grad_norm": 6.859813213348389,
      "learning_rate": 3.791935483870968e-05,
      "loss": 0.3454,
      "step": 1550
    },
    {
      "epoch": 0.512,
      "grad_norm": 10.335606575012207,
      "learning_rate": 3.751612903225807e-05,
      "loss": 0.308,
      "step": 1600
    },
    {
      "epoch": 0.528,
      "grad_norm": 5.061906814575195,
      "learning_rate": 3.711290322580646e-05,
      "loss": 0.3035,
      "step": 1650
    },
    {
      "epoch": 0.544,
      "grad_norm": 4.868542671203613,
      "learning_rate": 3.670967741935484e-05,
      "loss": 0.34,
      "step": 1700
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.067354202270508,
      "learning_rate": 3.630645161290322e-05,
      "loss": 0.3565,
      "step": 1750
    },
    {
      "epoch": 0.576,
      "grad_norm": 7.49595308303833,
      "learning_rate": 3.590322580645161e-05,
      "loss": 0.2608,
      "step": 1800
    },
    {
      "epoch": 0.592,
      "grad_norm": 5.433791160583496,
      "learning_rate": 3.55e-05,
      "loss": 0.3157,
      "step": 1850
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.4015689492225647,
      "learning_rate": 3.5096774193548385e-05,
      "loss": 0.2856,
      "step": 1900
    },
    {
      "epoch": 0.624,
      "grad_norm": 12.318196296691895,
      "learning_rate": 3.4693548387096775e-05,
      "loss": 0.288,
      "step": 1950
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.2405481338500977,
      "learning_rate": 3.4290322580645164e-05,
      "loss": 0.3876,
      "step": 2000
    },
    {
      "epoch": 0.656,
      "grad_norm": 10.442646980285645,
      "learning_rate": 3.388709677419355e-05,
      "loss": 0.3319,
      "step": 2050
    },
    {
      "epoch": 0.672,
      "grad_norm": 6.87216854095459,
      "learning_rate": 3.3483870967741936e-05,
      "loss": 0.2799,
      "step": 2100
    },
    {
      "epoch": 0.688,
      "grad_norm": 5.744488716125488,
      "learning_rate": 3.3080645161290326e-05,
      "loss": 0.3027,
      "step": 2150
    },
    {
      "epoch": 0.704,
      "grad_norm": 4.178797721862793,
      "learning_rate": 3.267741935483871e-05,
      "loss": 0.3076,
      "step": 2200
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.387663841247559,
      "learning_rate": 3.22741935483871e-05,
      "loss": 0.2566,
      "step": 2250
    },
    {
      "epoch": 0.736,
      "grad_norm": 12.338805198669434,
      "learning_rate": 3.187096774193549e-05,
      "loss": 0.319,
      "step": 2300
    },
    {
      "epoch": 0.752,
      "grad_norm": 9.47064208984375,
      "learning_rate": 3.146774193548388e-05,
      "loss": 0.3279,
      "step": 2350
    },
    {
      "epoch": 0.768,
      "grad_norm": 4.169252872467041,
      "learning_rate": 3.106451612903226e-05,
      "loss": 0.2932,
      "step": 2400
    },
    {
      "epoch": 0.784,
      "grad_norm": 2.774731159210205,
      "learning_rate": 3.066129032258065e-05,
      "loss": 0.3068,
      "step": 2450
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.9395341873168945,
      "learning_rate": 3.0258064516129032e-05,
      "loss": 0.3354,
      "step": 2500
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.4323805272579193,
      "learning_rate": 2.985483870967742e-05,
      "loss": 0.3141,
      "step": 2550
    },
    {
      "epoch": 0.832,
      "grad_norm": 3.2528464794158936,
      "learning_rate": 2.9451612903225805e-05,
      "loss": 0.2539,
      "step": 2600
    },
    {
      "epoch": 0.848,
      "grad_norm": 11.073655128479004,
      "learning_rate": 2.9048387096774194e-05,
      "loss": 0.2999,
      "step": 2650
    },
    {
      "epoch": 0.864,
      "grad_norm": 7.643585205078125,
      "learning_rate": 2.864516129032258e-05,
      "loss": 0.3533,
      "step": 2700
    },
    {
      "epoch": 0.88,
      "grad_norm": 8.08065128326416,
      "learning_rate": 2.8241935483870967e-05,
      "loss": 0.2491,
      "step": 2750
    },
    {
      "epoch": 0.896,
      "grad_norm": 1.0611209869384766,
      "learning_rate": 2.7838709677419356e-05,
      "loss": 0.2606,
      "step": 2800
    },
    {
      "epoch": 0.912,
      "grad_norm": 7.269674301147461,
      "learning_rate": 2.7435483870967742e-05,
      "loss": 0.384,
      "step": 2850
    },
    {
      "epoch": 0.928,
      "grad_norm": 9.711913108825684,
      "learning_rate": 2.7032258064516132e-05,
      "loss": 0.3593,
      "step": 2900
    },
    {
      "epoch": 0.944,
      "grad_norm": 10.712981224060059,
      "learning_rate": 2.6629032258064518e-05,
      "loss": 0.3175,
      "step": 2950
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.150750160217285,
      "learning_rate": 2.6233870967741936e-05,
      "loss": 0.2926,
      "step": 3000
    },
    {
      "epoch": 0.976,
      "grad_norm": 4.064871311187744,
      "learning_rate": 2.5830645161290323e-05,
      "loss": 0.2468,
      "step": 3050
    },
    {
      "epoch": 0.992,
      "grad_norm": 2.957528591156006,
      "learning_rate": 2.5427419354838712e-05,
      "loss": 0.2061,
      "step": 3100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.3233458697795868,
      "eval_runtime": 208.4344,
      "eval_samples_per_second": 119.942,
      "eval_steps_per_second": 14.993,
      "step": 3125
    },
    {
      "epoch": 1.008,
      "grad_norm": 1.1713321208953857,
      "learning_rate": 2.5024193548387098e-05,
      "loss": 0.3317,
      "step": 3150
    },
    {
      "epoch": 1.024,
      "grad_norm": 10.955879211425781,
      "learning_rate": 2.4620967741935484e-05,
      "loss": 0.229,
      "step": 3200
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9719022512435913,
      "learning_rate": 2.4217741935483874e-05,
      "loss": 0.3813,
      "step": 3250
    },
    {
      "epoch": 1.056,
      "grad_norm": 7.216491222381592,
      "learning_rate": 2.381451612903226e-05,
      "loss": 0.2506,
      "step": 3300
    },
    {
      "epoch": 1.072,
      "grad_norm": 6.657953262329102,
      "learning_rate": 2.3411290322580646e-05,
      "loss": 0.3505,
      "step": 3350
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.392479807138443,
      "learning_rate": 2.3008064516129032e-05,
      "loss": 0.2964,
      "step": 3400
    },
    {
      "epoch": 1.104,
      "grad_norm": 6.076022624969482,
      "learning_rate": 2.260483870967742e-05,
      "loss": 0.3137,
      "step": 3450
    },
    {
      "epoch": 1.12,
      "grad_norm": 6.441812992095947,
      "learning_rate": 2.2201612903225808e-05,
      "loss": 0.3056,
      "step": 3500
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 13.432208061218262,
      "learning_rate": 2.1798387096774194e-05,
      "loss": 0.3105,
      "step": 3550
    },
    {
      "epoch": 1.152,
      "grad_norm": 11.012312889099121,
      "learning_rate": 2.1395161290322584e-05,
      "loss": 0.3106,
      "step": 3600
    },
    {
      "epoch": 1.168,
      "grad_norm": 2.9936442375183105,
      "learning_rate": 2.099193548387097e-05,
      "loss": 0.2522,
      "step": 3650
    },
    {
      "epoch": 1.184,
      "grad_norm": 5.36787223815918,
      "learning_rate": 2.0588709677419356e-05,
      "loss": 0.2624,
      "step": 3700
    },
    {
      "epoch": 1.2,
      "grad_norm": 6.613570213317871,
      "learning_rate": 2.0185483870967742e-05,
      "loss": 0.3027,
      "step": 3750
    },
    {
      "epoch": 1.216,
      "grad_norm": 14.745800971984863,
      "learning_rate": 1.978225806451613e-05,
      "loss": 0.3234,
      "step": 3800
    },
    {
      "epoch": 1.232,
      "grad_norm": 8.387422561645508,
      "learning_rate": 1.9379032258064518e-05,
      "loss": 0.3223,
      "step": 3850
    },
    {
      "epoch": 1.248,
      "grad_norm": 11.637615203857422,
      "learning_rate": 1.8975806451612904e-05,
      "loss": 0.2856,
      "step": 3900
    },
    {
      "epoch": 1.264,
      "grad_norm": 5.012247085571289,
      "learning_rate": 1.857258064516129e-05,
      "loss": 0.2828,
      "step": 3950
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.0505355596542358,
      "learning_rate": 1.816935483870968e-05,
      "loss": 0.3012,
      "step": 4000
    },
    {
      "epoch": 1.296,
      "grad_norm": 3.4101388454437256,
      "learning_rate": 1.7766129032258066e-05,
      "loss": 0.2367,
      "step": 4050
    },
    {
      "epoch": 1.312,
      "grad_norm": 6.001070499420166,
      "learning_rate": 1.7362903225806452e-05,
      "loss": 0.3112,
      "step": 4100
    },
    {
      "epoch": 1.328,
      "grad_norm": 3.140833854675293,
      "learning_rate": 1.6959677419354838e-05,
      "loss": 0.3089,
      "step": 4150
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 8.047131538391113,
      "learning_rate": 1.6556451612903228e-05,
      "loss": 0.2842,
      "step": 4200
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 9.91657829284668,
      "learning_rate": 1.6153225806451614e-05,
      "loss": 0.2344,
      "step": 4250
    },
    {
      "epoch": 1.376,
      "grad_norm": 3.6985607147216797,
      "learning_rate": 1.575e-05,
      "loss": 0.3112,
      "step": 4300
    },
    {
      "epoch": 1.392,
      "grad_norm": 7.469856262207031,
      "learning_rate": 1.534677419354839e-05,
      "loss": 0.2585,
      "step": 4350
    },
    {
      "epoch": 1.408,
      "grad_norm": 5.265831470489502,
      "learning_rate": 1.4943548387096776e-05,
      "loss": 0.2642,
      "step": 4400
    },
    {
      "epoch": 1.424,
      "grad_norm": 6.824332237243652,
      "learning_rate": 1.4540322580645164e-05,
      "loss": 0.3264,
      "step": 4450
    },
    {
      "epoch": 1.44,
      "grad_norm": 12.58984661102295,
      "learning_rate": 1.4137096774193548e-05,
      "loss": 0.3007,
      "step": 4500
    },
    {
      "epoch": 1.456,
      "grad_norm": 8.598596572875977,
      "learning_rate": 1.3733870967741936e-05,
      "loss": 0.2733,
      "step": 4550
    },
    {
      "epoch": 1.472,
      "grad_norm": 7.548807621002197,
      "learning_rate": 1.3330645161290322e-05,
      "loss": 0.2667,
      "step": 4600
    },
    {
      "epoch": 1.488,
      "grad_norm": 9.25013256072998,
      "learning_rate": 1.292741935483871e-05,
      "loss": 0.2994,
      "step": 4650
    },
    {
      "epoch": 1.504,
      "grad_norm": 12.347831726074219,
      "learning_rate": 1.2524193548387098e-05,
      "loss": 0.278,
      "step": 4700
    },
    {
      "epoch": 1.52,
      "grad_norm": 9.614054679870605,
      "learning_rate": 1.2120967741935485e-05,
      "loss": 0.2324,
      "step": 4750
    },
    {
      "epoch": 1.536,
      "grad_norm": 3.9620442390441895,
      "learning_rate": 1.1717741935483872e-05,
      "loss": 0.2958,
      "step": 4800
    },
    {
      "epoch": 1.552,
      "grad_norm": 1.1519585847854614,
      "learning_rate": 1.1314516129032258e-05,
      "loss": 0.2917,
      "step": 4850
    },
    {
      "epoch": 1.568,
      "grad_norm": 5.744716167449951,
      "learning_rate": 1.0911290322580646e-05,
      "loss": 0.3147,
      "step": 4900
    },
    {
      "epoch": 1.584,
      "grad_norm": 4.202355861663818,
      "learning_rate": 1.0508064516129033e-05,
      "loss": 0.2831,
      "step": 4950
    },
    {
      "epoch": 1.6,
      "grad_norm": 13.283613204956055,
      "learning_rate": 1.010483870967742e-05,
      "loss": 0.2599,
      "step": 5000
    },
    {
      "epoch": 1.616,
      "grad_norm": 3.646960496902466,
      "learning_rate": 9.709677419354838e-06,
      "loss": 0.3116,
      "step": 5050
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 4.263346195220947,
      "learning_rate": 9.306451612903226e-06,
      "loss": 0.3151,
      "step": 5100
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 12.446205139160156,
      "learning_rate": 8.903225806451614e-06,
      "loss": 0.3273,
      "step": 5150
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 3.687769889831543,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.304,
      "step": 5200
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.0500202178955078,
      "learning_rate": 8.096774193548388e-06,
      "loss": 0.3016,
      "step": 5250
    },
    {
      "epoch": 1.696,
      "grad_norm": 9.008191108703613,
      "learning_rate": 7.693548387096774e-06,
      "loss": 0.3293,
      "step": 5300
    },
    {
      "epoch": 1.712,
      "grad_norm": 5.262663841247559,
      "learning_rate": 7.290322580645162e-06,
      "loss": 0.302,
      "step": 5350
    },
    {
      "epoch": 1.728,
      "grad_norm": 2.571531057357788,
      "learning_rate": 6.88709677419355e-06,
      "loss": 0.301,
      "step": 5400
    },
    {
      "epoch": 1.744,
      "grad_norm": 4.0295610427856445,
      "learning_rate": 6.483870967741936e-06,
      "loss": 0.318,
      "step": 5450
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.458980083465576,
      "learning_rate": 6.080645161290323e-06,
      "loss": 0.2998,
      "step": 5500
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.6501783132553101,
      "learning_rate": 5.677419354838711e-06,
      "loss": 0.2703,
      "step": 5550
    },
    {
      "epoch": 1.792,
      "grad_norm": 6.981429576873779,
      "learning_rate": 5.274193548387097e-06,
      "loss": 0.2458,
      "step": 5600
    },
    {
      "epoch": 1.808,
      "grad_norm": 2.9872324466705322,
      "learning_rate": 4.870967741935484e-06,
      "loss": 0.2312,
      "step": 5650
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 7.272986888885498,
      "learning_rate": 4.467741935483872e-06,
      "loss": 0.253,
      "step": 5700
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 3.428738594055176,
      "learning_rate": 4.064516129032258e-06,
      "loss": 0.2861,
      "step": 5750
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 6.106685638427734,
      "learning_rate": 3.6612903225806456e-06,
      "loss": 0.2361,
      "step": 5800
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 5.155360698699951,
      "learning_rate": 3.258064516129032e-06,
      "loss": 0.2781,
      "step": 5850
    },
    {
      "epoch": 1.888,
      "grad_norm": 5.880188941955566,
      "learning_rate": 2.8548387096774196e-06,
      "loss": 0.2585,
      "step": 5900
    },
    {
      "epoch": 1.904,
      "grad_norm": 5.625732898712158,
      "learning_rate": 2.4516129032258066e-06,
      "loss": 0.2802,
      "step": 5950
    },
    {
      "epoch": 1.92,
      "grad_norm": 5.679028034210205,
      "learning_rate": 2.0483870967741936e-06,
      "loss": 0.2516,
      "step": 6000
    },
    {
      "epoch": 1.936,
      "grad_norm": 7.550224304199219,
      "learning_rate": 1.6451612903225808e-06,
      "loss": 0.257,
      "step": 6050
    },
    {
      "epoch": 1.952,
      "grad_norm": 5.560075283050537,
      "learning_rate": 1.2419354838709678e-06,
      "loss": 0.2944,
      "step": 6100
    },
    {
      "epoch": 1.968,
      "grad_norm": 6.391005516052246,
      "learning_rate": 8.387096774193549e-07,
      "loss": 0.2798,
      "step": 6150
    },
    {
      "epoch": 1.984,
      "grad_norm": 6.845470905303955,
      "learning_rate": 4.354838709677419e-07,
      "loss": 0.316,
      "step": 6200
    },
    {
      "epoch": 2.0,
      "grad_norm": 11.100207328796387,
      "learning_rate": 3.2258064516129035e-08,
      "loss": 0.3423,
      "step": 6250
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.2865026593208313,
      "eval_runtime": 209.8008,
      "eval_samples_per_second": 119.161,
      "eval_steps_per_second": 14.895,
      "step": 6250
    }
  ],
  "logging_steps": 50,
  "max_steps": 6250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "total_flos": 3368485171200000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
